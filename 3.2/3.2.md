# Домашнее задание к занятию «Установка Kubernetes», Лебедев А.И., FOPS-10

### Цель задания

Установить кластер K8s.

### Чеклист готовности к домашнему заданию

1. Развёрнутые ВМ с ОС Ubuntu 20.04-lts.


### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания

1. [Инструкция по установке kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/).
2. [Документация kubespray](https://kubespray.io/).

-----

### Задание 1. Установить кластер k8s с 1 master node

1. Подготовка работы кластера из 5 нод: 1 мастер и 4 рабочие ноды.
2. В качестве CRI — containerd.
3. Запуск etcd производить на мастере.
4. Способ установки выбрать самостоятельно.

### Выполнение:  

- Коллеги, прошу прощения, сейчас нахожусь немного в авральном режиме, закрывая все необходимы задачи, чтобы успеть выйти на диплом к дедлайну. При выполнении данной работы я импользовал виртуальные машины из virtualbox, остановился на kubeadm и, в целях автоматизации, использовал плейбук ансибла, но, так вышло, что данныемашины уже удалены и у меня просто нет времени их восстанавливать.

- Я попытаюсь объяснить, как и что я делал по шагам и как оно должно работать. Собственно, мы разворачиваем одну мастер-ноду и 4 воркера, используя kubeadm.

## 1. Подготовка виртуальных машин
## Требования:
- 1 мастер-нода:
  - 2 CPU, 2 GB RAM, 20 GB диска.
- 4 рабочие ноды:
  - 2 CPU, 2 GB RAM, 10 GB каждая.
- ОС: **Ubuntu 20.04 LTS** на всех нодах.

## Предварительная настройка:
## На всех нодах:  

  
```
sudo apt update && sudo apt upgrade -y
sudo apt install -y apt-transport-https ca-certificates curl
```

- Устанавливаем и настраиваем containerd:

```
sudo apt install -y containerd
```

```
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
sudo systemctl restart containerd
sudo systemctl enable containerd
```

Устанавливаем kubeadm, kubelet и kubectl:  

```
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo apt-add-repository "deb http://apt.kubernetes.io/ kubernetes-xenial main"
```

```
sudo apt update
sudo apt install -y kubeadm kubelet kubectl
sudo apt-mark hold kubeadm kubelet kubectl
```

## На мастер-ноде  

- Запускаем kabeadm init и настраиваем kubectl относительно нашей подсети:

```
sudo kubeadm init --pod-network-cidr=192.168.0.0/16
```

```
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

Сохраняем команду для подключения воркеров:  

```
kubeadm join <master-ip>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash>
```

Устанавливаем сетевой плагин:  

```
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
```

## На воркерах  

- Выполняем команду, которую сгенерировали ранее на мастер-ноде и цепляем к ней воркеры:

```
sudo kubeadm join <master-ip>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash>
```

### Что мы должны видеть в continerd:  

![1](img/1.jpg)
